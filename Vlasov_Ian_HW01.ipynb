{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn \n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "\n",
    "# реализация критерия ранней остановки\n",
    "from tools.pytorchtools import EarlyStopping\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добиться вразумительного результата от модели, собранной на занятии (7 угаданныx картинок из 10 предложенных на семинаре).\n",
    "\n",
    "Реализованные идеи (проверял поэтапно, постепенно улучшая скор):\n",
    "* Добавил валидационный набор данных, чтобы отслеживать лосс не только на тренировочных данных\n",
    "* Добавил раннюю остановку и обучал до тех пор пока качество на валидации не начнет падать\n",
    "* За базовую модель взял модель, состоящую из 3 VGG блоков с 32, 64 и 128 наборами параметров соответственно\n",
    "* Добавил предобработку:\n",
    "    - нормализовал значения в тензоре при помощи среднего и стандартного отклонения по всей выборке\n",
    "    - добавил несложную аугментацию: 30 процентов вероятность отразить картинку по вертикали и горизонтали\n",
    "* Заменил оптимизатор на Adam. Он адаптивный, быстрее сходится и в нем не так сильна зависимость размера батча и скорости обучения\n",
    "* Добавил в модель dropout слои. Пробовал различные конфигурации с константным и постепенно возрастающим шансом отбросить нейрон. Лучше сработало в варианте с постепенным возрастанием\n",
    "* Добавил нормализацию батча после каждого слоя. Пробовал в двух вариантах: до и после ReLu, так как однозначного ответа, как лучше это делать не нашел. Лучше сработало при добавлении после функции активации\n",
    "* Пробовал заменить пулинговые слои на свертку со страйдом. Идея была получить еще один обучаемый слой, который по размерностям работал бы аналогично пулингу, но эффекта это не дало\n",
    "\n",
    "Финальный скор модели на тестовой выборке: 84.29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# основные параметры\n",
    "batch_size = 2048\n",
    "n_epochs = 400\n",
    "num_classes = 10\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_mean = (0.4914, 0.4822, 0.4465)\n",
    "rgb_std = (0.2470, 0.2435, 0.2616)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(rgb_mean, \n",
    "                         rgb_std),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(rgb_mean, \n",
    "                         rgb_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# скачиваем датасеты\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                             train=True,  \n",
    "                                             transform=train_transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устнанавливаем размер тренировочной и валидационной выборок\n",
    "train_size = int(0.7 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на train-validation\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4914, 0.4822, 0.4465])\n",
      "tensor([0.2470, 0.2435, 0.2616])\n"
     ]
    }
   ],
   "source": [
    "# Откуда взялись значения для нормализации\n",
    "mean_train = torch.mean(torch.Tensor.float(torch.from_numpy(train_set.dataset.data) / 255), dim=(0, 1, 2))\n",
    "std_train = torch.std(torch.Tensor.float(torch.from_numpy(train_set.dataset.data) / 255), dim=(0, 1, 2))\n",
    "\n",
    "print(mean_train)\n",
    "print(std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "val_loader = data.DataLoader(val_set, batch_size = batch_size, shuffle = True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv21 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv31 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        \n",
    "        self.bnorm1 = nn.BatchNorm2d(32)\n",
    "        self.bnorm11 = nn.BatchNorm2d(32)\n",
    "        self.bnorm2 = nn.BatchNorm2d(64)\n",
    "        self.bnorm21 = nn.BatchNorm2d(64)\n",
    "        self.bnorm3 = nn.BatchNorm2d(128)\n",
    "        self.bnorm31 = nn.BatchNorm2d(128)\n",
    "        self.bnorm4 = nn.BatchNorm1d(128)\n",
    "\n",
    "        \n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.dropout2 = nn.Dropout2d(0.3)\n",
    "        self.dropout3 = nn.Dropout2d(0.4)\n",
    "        self.dropout4 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bnorm1(x)\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = self.bnorm11(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bnorm2(x)\n",
    "        x = F.relu(self.conv21(x))\n",
    "        x = self.bnorm21(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.bnorm3(x)\n",
    "        x = F.relu(self.conv31(x))\n",
    "        x = self.bnorm31(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bnorm4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, patience, n_epochs, device): \n",
    "    \"\"\"Function trains given model during n_epochs with early stopping\n",
    "    criteria: train stops if validation loss does not decrease \n",
    "    during {patience} epochs.\n",
    "    For correct work 'train_loader' and 'val_loader' must be defined\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    model: neural network for training\n",
    "    patience: int, number of epochs for early stopping\n",
    "    n_epochs: int, number of epochs for training\n",
    "    device: torch.device\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    model: neural network loaded from checkpoint.pt.\n",
    "           Last step of model when validation loss decreased\n",
    "    avg_train_losses: list with average values of loss function \n",
    "                      during training through epochs\n",
    "    avg_valid_losses: list with average values of loss function \n",
    "                      during validating through epochs\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    avg_train_losses = []\n",
    "    avg_valid_losses = [] \n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch, data in enumerate(train_loader, 1):\n",
    "            data, target = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for data in val_loader:\n",
    "            data, target = data[0].to(device), data[1].to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_losses.append(loss.item())\n",
    "\n",
    "        # print training/validation statistics \n",
    "        # calculate average loss over an epoch\n",
    "        train_loss = np.average(train_losses)\n",
    "        valid_loss = np.average(valid_losses)\n",
    "        avg_train_losses.append(train_loss)\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        \n",
    "        epoch_len = len(str(n_epochs))\n",
    "        \n",
    "        print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                     f'train_loss: {train_loss:.5f} ' +\n",
    "                     f'valid_loss: {valid_loss:.5f}')\n",
    "        \n",
    "        print(print_msg)\n",
    "        \n",
    "        # clear lists to track next epoch\n",
    "        train_losses = []\n",
    "        valid_losses = []\n",
    "        \n",
    "        # early_stopping needs the validation loss to check if it has decresed, \n",
    "        # and if it has, it will make a checkpoint of the current model\n",
    "        early_stopping(valid_loss, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "        \n",
    "    # load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "    return  model, avg_train_losses, avg_valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/400] train_loss: 2.00869 valid_loss: 2.51237\n",
      "Validation loss decreased (inf --> 2.512373).  Saving model ...\n",
      "[  2/400] train_loss: 1.69349 valid_loss: 1.58187\n",
      "Validation loss decreased (2.512373 --> 1.581870).  Saving model ...\n",
      "[  3/400] train_loss: 1.55968 valid_loss: 1.39346\n",
      "Validation loss decreased (1.581870 --> 1.393457).  Saving model ...\n",
      "[  4/400] train_loss: 1.46901 valid_loss: 1.28735\n",
      "Validation loss decreased (1.393457 --> 1.287346).  Saving model ...\n",
      "[  5/400] train_loss: 1.39570 valid_loss: 1.24249\n",
      "Validation loss decreased (1.287346 --> 1.242485).  Saving model ...\n",
      "[  6/400] train_loss: 1.34102 valid_loss: 1.18709\n",
      "Validation loss decreased (1.242485 --> 1.187086).  Saving model ...\n",
      "[  7/400] train_loss: 1.27046 valid_loss: 1.13669\n",
      "Validation loss decreased (1.187086 --> 1.136685).  Saving model ...\n",
      "[  8/400] train_loss: 1.22375 valid_loss: 1.08338\n",
      "Validation loss decreased (1.136685 --> 1.083378).  Saving model ...\n",
      "[  9/400] train_loss: 1.18799 valid_loss: 1.02939\n",
      "Validation loss decreased (1.083378 --> 1.029387).  Saving model ...\n",
      "[ 10/400] train_loss: 1.14570 valid_loss: 0.99464\n",
      "Validation loss decreased (1.029387 --> 0.994641).  Saving model ...\n",
      "[ 11/400] train_loss: 1.11478 valid_loss: 0.96732\n",
      "Validation loss decreased (0.994641 --> 0.967323).  Saving model ...\n",
      "[ 12/400] train_loss: 1.07579 valid_loss: 0.95012\n",
      "Validation loss decreased (0.967323 --> 0.950117).  Saving model ...\n",
      "[ 13/400] train_loss: 1.05558 valid_loss: 0.90356\n",
      "Validation loss decreased (0.950117 --> 0.903560).  Saving model ...\n",
      "[ 14/400] train_loss: 1.02294 valid_loss: 0.91986\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 15/400] train_loss: 1.00478 valid_loss: 0.90156\n",
      "Validation loss decreased (0.903560 --> 0.901561).  Saving model ...\n",
      "[ 16/400] train_loss: 0.98351 valid_loss: 0.86397\n",
      "Validation loss decreased (0.901561 --> 0.863972).  Saving model ...\n",
      "[ 17/400] train_loss: 0.95913 valid_loss: 0.83087\n",
      "Validation loss decreased (0.863972 --> 0.830873).  Saving model ...\n",
      "[ 18/400] train_loss: 0.93687 valid_loss: 0.81027\n",
      "Validation loss decreased (0.830873 --> 0.810272).  Saving model ...\n",
      "[ 19/400] train_loss: 0.93136 valid_loss: 0.81717\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 20/400] train_loss: 0.91008 valid_loss: 0.78758\n",
      "Validation loss decreased (0.810272 --> 0.787584).  Saving model ...\n",
      "[ 21/400] train_loss: 0.89715 valid_loss: 0.78341\n",
      "Validation loss decreased (0.787584 --> 0.783407).  Saving model ...\n",
      "[ 22/400] train_loss: 0.87073 valid_loss: 0.75696\n",
      "Validation loss decreased (0.783407 --> 0.756961).  Saving model ...\n",
      "[ 23/400] train_loss: 0.85257 valid_loss: 0.75157\n",
      "Validation loss decreased (0.756961 --> 0.751569).  Saving model ...\n",
      "[ 24/400] train_loss: 0.86044 valid_loss: 0.75435\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 25/400] train_loss: 0.83319 valid_loss: 0.74250\n",
      "Validation loss decreased (0.751569 --> 0.742502).  Saving model ...\n",
      "[ 26/400] train_loss: 0.81637 valid_loss: 0.71994\n",
      "Validation loss decreased (0.742502 --> 0.719937).  Saving model ...\n",
      "[ 27/400] train_loss: 0.80842 valid_loss: 0.72176\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 28/400] train_loss: 0.80015 valid_loss: 0.71892\n",
      "Validation loss decreased (0.719937 --> 0.718918).  Saving model ...\n",
      "[ 29/400] train_loss: 0.80397 valid_loss: 0.70946\n",
      "Validation loss decreased (0.718918 --> 0.709457).  Saving model ...\n",
      "[ 30/400] train_loss: 0.79208 valid_loss: 0.69072\n",
      "Validation loss decreased (0.709457 --> 0.690721).  Saving model ...\n",
      "[ 31/400] train_loss: 0.77469 valid_loss: 0.69230\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 32/400] train_loss: 0.77221 valid_loss: 0.69294\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 33/400] train_loss: 0.76436 valid_loss: 0.66891\n",
      "Validation loss decreased (0.690721 --> 0.668912).  Saving model ...\n",
      "[ 34/400] train_loss: 0.75791 valid_loss: 0.66951\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 35/400] train_loss: 0.75759 valid_loss: 0.66290\n",
      "Validation loss decreased (0.668912 --> 0.662897).  Saving model ...\n",
      "[ 36/400] train_loss: 0.73637 valid_loss: 0.66822\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 37/400] train_loss: 0.73210 valid_loss: 0.64707\n",
      "Validation loss decreased (0.662897 --> 0.647073).  Saving model ...\n",
      "[ 38/400] train_loss: 0.72685 valid_loss: 0.64291\n",
      "Validation loss decreased (0.647073 --> 0.642907).  Saving model ...\n",
      "[ 39/400] train_loss: 0.71606 valid_loss: 0.64353\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 40/400] train_loss: 0.70955 valid_loss: 0.64272\n",
      "Validation loss decreased (0.642907 --> 0.642719).  Saving model ...\n",
      "[ 41/400] train_loss: 0.71175 valid_loss: 0.63320\n",
      "Validation loss decreased (0.642719 --> 0.633204).  Saving model ...\n",
      "[ 42/400] train_loss: 0.70149 valid_loss: 0.65133\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 43/400] train_loss: 0.69245 valid_loss: 0.63587\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 44/400] train_loss: 0.69177 valid_loss: 0.61276\n",
      "Validation loss decreased (0.633204 --> 0.612761).  Saving model ...\n",
      "[ 45/400] train_loss: 0.69145 valid_loss: 0.63676\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 46/400] train_loss: 0.68017 valid_loss: 0.61167\n",
      "Validation loss decreased (0.612761 --> 0.611673).  Saving model ...\n",
      "[ 47/400] train_loss: 0.68335 valid_loss: 0.61532\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 48/400] train_loss: 0.67587 valid_loss: 0.61168\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 49/400] train_loss: 0.65984 valid_loss: 0.60690\n",
      "Validation loss decreased (0.611673 --> 0.606902).  Saving model ...\n",
      "[ 50/400] train_loss: 0.66856 valid_loss: 0.61130\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 51/400] train_loss: 0.66046 valid_loss: 0.59215\n",
      "Validation loss decreased (0.606902 --> 0.592146).  Saving model ...\n",
      "[ 52/400] train_loss: 0.65958 valid_loss: 0.59103\n",
      "Validation loss decreased (0.592146 --> 0.591030).  Saving model ...\n",
      "[ 53/400] train_loss: 0.63715 valid_loss: 0.58894\n",
      "Validation loss decreased (0.591030 --> 0.588937).  Saving model ...\n",
      "[ 54/400] train_loss: 0.65175 valid_loss: 0.59190\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 55/400] train_loss: 0.63849 valid_loss: 0.58174\n",
      "Validation loss decreased (0.588937 --> 0.581741).  Saving model ...\n",
      "[ 56/400] train_loss: 0.62891 valid_loss: 0.57907\n",
      "Validation loss decreased (0.581741 --> 0.579073).  Saving model ...\n",
      "[ 57/400] train_loss: 0.63632 valid_loss: 0.58379\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 58/400] train_loss: 0.63424 valid_loss: 0.60236\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 59/400] train_loss: 0.62809 valid_loss: 0.58643\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 60/400] train_loss: 0.61747 valid_loss: 0.57960\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[ 61/400] train_loss: 0.62061 valid_loss: 0.58786\n",
      "EarlyStopping counter: 5 out of 10\n",
      "[ 62/400] train_loss: 0.61595 valid_loss: 0.57153\n",
      "Validation loss decreased (0.579073 --> 0.571531).  Saving model ...\n",
      "[ 63/400] train_loss: 0.60319 valid_loss: 0.56665\n",
      "Validation loss decreased (0.571531 --> 0.566646).  Saving model ...\n",
      "[ 64/400] train_loss: 0.60019 valid_loss: 0.55707\n",
      "Validation loss decreased (0.566646 --> 0.557074).  Saving model ...\n",
      "[ 65/400] train_loss: 0.59649 valid_loss: 0.56470\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 66/400] train_loss: 0.59573 valid_loss: 0.56466\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 67/400] train_loss: 0.59734 valid_loss: 0.56663\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 68/400] train_loss: 0.60591 valid_loss: 0.57074\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[ 69/400] train_loss: 0.57965 valid_loss: 0.55658\n",
      "Validation loss decreased (0.557074 --> 0.556583).  Saving model ...\n",
      "[ 70/400] train_loss: 0.57780 valid_loss: 0.56276\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 71/400] train_loss: 0.58437 valid_loss: 0.55455\n",
      "Validation loss decreased (0.556583 --> 0.554546).  Saving model ...\n",
      "[ 72/400] train_loss: 0.57584 valid_loss: 0.56758\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 73/400] train_loss: 0.57628 valid_loss: 0.55089\n",
      "Validation loss decreased (0.554546 --> 0.550891).  Saving model ...\n",
      "[ 74/400] train_loss: 0.56521 valid_loss: 0.54290\n",
      "Validation loss decreased (0.550891 --> 0.542896).  Saving model ...\n",
      "[ 75/400] train_loss: 0.56515 valid_loss: 0.55711\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 76/400] train_loss: 0.56529 valid_loss: 0.54521\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 77/400] train_loss: 0.56552 valid_loss: 0.54577\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 78/400] train_loss: 0.56555 valid_loss: 0.54160\n",
      "Validation loss decreased (0.542896 --> 0.541600).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 79/400] train_loss: 0.54790 valid_loss: 0.55223\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 80/400] train_loss: 0.55313 valid_loss: 0.54591\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 81/400] train_loss: 0.55625 valid_loss: 0.54879\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 82/400] train_loss: 0.54993 valid_loss: 0.54389\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[ 83/400] train_loss: 0.55356 valid_loss: 0.54994\n",
      "EarlyStopping counter: 5 out of 10\n",
      "[ 84/400] train_loss: 0.56670 valid_loss: 0.54963\n",
      "EarlyStopping counter: 6 out of 10\n",
      "[ 85/400] train_loss: 0.54919 valid_loss: 0.54193\n",
      "EarlyStopping counter: 7 out of 10\n",
      "[ 86/400] train_loss: 0.53799 valid_loss: 0.54158\n",
      "Validation loss decreased (0.541600 --> 0.541583).  Saving model ...\n",
      "[ 87/400] train_loss: 0.54042 valid_loss: 0.53719\n",
      "Validation loss decreased (0.541583 --> 0.537194).  Saving model ...\n",
      "[ 88/400] train_loss: 0.54730 valid_loss: 0.54277\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 89/400] train_loss: 0.53977 valid_loss: 0.53526\n",
      "Validation loss decreased (0.537194 --> 0.535256).  Saving model ...\n",
      "[ 90/400] train_loss: 0.53162 valid_loss: 0.52656\n",
      "Validation loss decreased (0.535256 --> 0.526559).  Saving model ...\n",
      "[ 91/400] train_loss: 0.52465 valid_loss: 0.53615\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 92/400] train_loss: 0.52655 valid_loss: 0.53306\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 93/400] train_loss: 0.51875 valid_loss: 0.53527\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 94/400] train_loss: 0.52421 valid_loss: 0.53287\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[ 95/400] train_loss: 0.52830 valid_loss: 0.53080\n",
      "EarlyStopping counter: 5 out of 10\n",
      "[ 96/400] train_loss: 0.53973 valid_loss: 0.52530\n",
      "Validation loss decreased (0.526559 --> 0.525300).  Saving model ...\n",
      "[ 97/400] train_loss: 0.53505 valid_loss: 0.53870\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 98/400] train_loss: 0.52586 valid_loss: 0.52977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 99/400] train_loss: 0.51375 valid_loss: 0.52210\n",
      "Validation loss decreased (0.525300 --> 0.522103).  Saving model ...\n",
      "[100/400] train_loss: 0.52167 valid_loss: 0.52906\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[101/400] train_loss: 0.53236 valid_loss: 0.52702\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[102/400] train_loss: 0.52923 valid_loss: 0.51857\n",
      "Validation loss decreased (0.522103 --> 0.518568).  Saving model ...\n",
      "[103/400] train_loss: 0.52434 valid_loss: 0.53658\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[104/400] train_loss: 0.51686 valid_loss: 0.51706\n",
      "Validation loss decreased (0.518568 --> 0.517063).  Saving model ...\n",
      "[105/400] train_loss: 0.51579 valid_loss: 0.51924\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[106/400] train_loss: 0.50754 valid_loss: 0.51639\n",
      "Validation loss decreased (0.517063 --> 0.516387).  Saving model ...\n",
      "[107/400] train_loss: 0.50603 valid_loss: 0.52049\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[108/400] train_loss: 0.50274 valid_loss: 0.51368\n",
      "Validation loss decreased (0.516387 --> 0.513675).  Saving model ...\n",
      "[109/400] train_loss: 0.49407 valid_loss: 0.50629\n",
      "Validation loss decreased (0.513675 --> 0.506286).  Saving model ...\n",
      "[110/400] train_loss: 0.49771 valid_loss: 0.51720\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[111/400] train_loss: 0.49561 valid_loss: 0.51719\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[112/400] train_loss: 0.49039 valid_loss: 0.51692\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[113/400] train_loss: 0.49961 valid_loss: 0.50980\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[114/400] train_loss: 0.49745 valid_loss: 0.51526\n",
      "EarlyStopping counter: 5 out of 10\n",
      "[115/400] train_loss: 0.49797 valid_loss: 0.51994\n",
      "EarlyStopping counter: 6 out of 10\n",
      "[116/400] train_loss: 0.49458 valid_loss: 0.51354\n",
      "EarlyStopping counter: 7 out of 10\n",
      "[117/400] train_loss: 0.49004 valid_loss: 0.51009\n",
      "EarlyStopping counter: 8 out of 10\n",
      "[118/400] train_loss: 0.48653 valid_loss: 0.51037\n",
      "EarlyStopping counter: 9 out of 10\n",
      "[119/400] train_loss: 0.48622 valid_loss: 0.51679\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model, train_loss, valid_loss = train_model(net, patience, n_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### График функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
    "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
    "\n",
    "minposs = valid_loss.index(min(valid_loss))+1 \n",
    "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.ylim(0, 2.5)\n",
    "plt.xlim(0, len(train_loss)+1)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на отложенном даатсете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.389090\n",
      "\n",
      "Test Accuracy of plane: 84.41% (682/808)\n",
      "Test Accuracy of car: 93.88% (783/834)\n",
      "Test Accuracy of bird: 76.63% (636/830)\n",
      "Test Accuracy of cat: 66.91% (546/816)\n",
      "Test Accuracy of deer: 84.27% (691/820)\n",
      "Test Accuracy of dog: 80.63% (670/831)\n",
      "Test Accuracy of frog: 88.82% (723/814)\n",
      "Test Accuracy of horse: 85.36% (694/813)\n",
      "Test Accuracy of ship: 89.47% (731/817)\n",
      "Test Accuracy of truck: 92.58% (749/809)\n",
      "\n",
      "Test Accuracy (Overall): 84.29% (6905/8192)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0.0\n",
    "class_correct = [0] * num_classes\n",
    "class_total = [0] * num_classes\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch, data in enumerate(test_loader, 1):\n",
    "    data, target = data[0].to(device), data[1].to(device)\n",
    "    if len(target.data) != batch_size:\n",
    "        break\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    test_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    # for multiclass: _, pred = torch.max(output, 1)\n",
    "    _, pred = torch.max(output, 1)\n",
    "    \n",
    "    correct = np.squeeze(pred.eq(target.data))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        label = label.int()\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "print(f'Test Loss: {test_loss:.6f}\\n')\n",
    "\n",
    "for i in range(num_classes):\n",
    "    if class_total[i] > 0:\n",
    "        class_accuracy = 100 * class_correct[i] / class_total[i]\n",
    "        print(f'Test Accuracy of {classes[i]}: {class_accuracy:.2f}% '\\\n",
    "              f'({np.sum(class_correct[i])}/{np.sum(class_total[i])})')\n",
    "              \n",
    "    else:\n",
    "        print(f'Test Accuracy of {classes[i]}: N/A (no training examples)')\n",
    "\n",
    "overall_accuracy = 100. * np.sum(class_correct) / np.sum(class_total)\n",
    "print(f'\\nTest Accuracy (Overall): {overall_accuracy:.2f}% '\\\n",
    "      f'({np.sum(class_correct)}/{np.sum(class_total)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_loader\n",
    "del test_loader\n",
    "del val_loader\n",
    "del net\n",
    "del data\n",
    "del target\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переписать данный туториал на pytorch: https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data_mnist',\n",
    "                                           train=True,  \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data_mnist', \n",
    "                                          train=False,\n",
    "                                          download=True, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] train_loss: 0.38672 \n",
      "[2/5] train_loss: 0.18552 \n",
      "[3/5] train_loss: 0.13761 \n",
      "[4/5] train_loss: 0.11200 \n",
      "[5/5] train_loss: 0.09418 \n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "avg_train_losses = [] \n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    model.train()\n",
    "    for batch, data in enumerate(train_loader, 1):\n",
    "        data, target = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    train_loss = np.average(train_losses)\n",
    "    avg_train_losses.append(train_loss)\n",
    "\n",
    "    epoch_len = len(str(n_epochs))\n",
    "\n",
    "    print_msg = (f'[{epoch:>{epoch_len}}/{n_epochs:>{epoch_len}}] ' +\n",
    "                 f'train_loss: {train_loss:.5f} ')\n",
    "\n",
    "    print(print_msg)\n",
    "\n",
    "    train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0914, Accuracy: 9724/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
